{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoCeJBTBwNnp"
   },
   "source": [
    "Sentiment Example from SLP Section 5.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imzjBpAxIthN"
   },
   "source": [
    "# Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "oA3eIgTYwNns"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2FGFTlNI3E3"
   },
   "source": [
    "# Loading the CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "Ss0i1_wdLclz"
   },
   "outputs": [],
   "source": [
    "with open('./negative-words.txt') as negative_words_file:\n",
    "    negative_words = negative_words_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "yUNz3nf3LZOq"
   },
   "outputs": [],
   "source": [
    "with open('./positive-words.txt') as positive_words_file:\n",
    "    positive_words = positive_words_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "Z0DHD0RuVXbM"
   },
   "outputs": [],
   "source": [
    "with open('./hotelPosT-train.txt') as positive_reviews_file:\n",
    "  positive_reviews = positive_reviews_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "MgKiujZFVdTf"
   },
   "outputs": [],
   "source": [
    "with open('./hotelNegT-train.txt') as negative_reviews_file:\n",
    "  negative_reviews = negative_reviews_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4J8KB59lLj6d"
   },
   "source": [
    "## List of Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "vjwOlslFLi7n"
   },
   "outputs": [],
   "source": [
    "pronouns = [\"i\", \"me\", \"mine\", \"my\", \"you\", \"your\", \"yours\", \"we\", \"us\", \"ours\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzmOA8IdL1zO"
   },
   "source": [
    "## Storing in Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "YCdnSbDLLsoT"
   },
   "outputs": [],
   "source": [
    "positive_words_dict = dict()\n",
    "negative_words_dict = dict()\n",
    "pronouns_dict = dict()\n",
    "\n",
    "\n",
    "for idx, word in enumerate(positive_words):\n",
    "  positive_words_dict[word] = idx\n",
    "\n",
    "\n",
    "for idx, word in enumerate(negative_words):\n",
    "  negative_words_dict[word] = idx\n",
    "\n",
    "for idx,word in enumerate(pronouns):\n",
    "  pronouns_dict[word]=idx;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkAKvLqeMK9K"
   },
   "source": [
    "## Word counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "R_HYrSm0MFjL"
   },
   "outputs": [],
   "source": [
    "def compute_counter_feature(document,source_dict):\n",
    "  counter = 0\n",
    "  for word in document:\n",
    "    if word.endswith('!') or word.endswith('.') or word.endswith(','):\n",
    "      word = word[:-1]\n",
    "    if word in source_dict:\n",
    "      counter = counter + 1;\n",
    "  return counter;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgXwpUeJMSUH"
   },
   "source": [
    "## Is No present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "2lUSn2AXMRFt"
   },
   "outputs": [],
   "source": [
    "def is_no_present(document):\n",
    "  for word in document:\n",
    "    if word == 'no':\n",
    "      return 1;\n",
    "  return 0;    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GH3itNaMbx-"
   },
   "source": [
    "## Compute the ln of number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "RQRenhGIMaef"
   },
   "outputs": [],
   "source": [
    "def compute_ln_number_of_words(document):\n",
    "  number_of_words = len(document)\n",
    "  return np.round(np.log(number_of_words),decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HhmSE-3NSYE"
   },
   "source": [
    "## Is ! present ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "U9-iYZHHNQxG"
   },
   "outputs": [],
   "source": [
    "def is_exclamation_present(document):\n",
    "  for words in document:\n",
    "    if words.endswith('!'):\n",
    "      return 1;\n",
    "  return 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WwcnWwaOpRw"
   },
   "source": [
    "## Loading Positive and Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "xhKO4qMoO4rJ"
   },
   "outputs": [],
   "source": [
    "reviews_positive_dict = dict()\n",
    "reviews_negative_dict = dict()\n",
    "\n",
    "for review in positive_reviews:\n",
    "  list_of_words = review.split()\n",
    "  lower_case = [word.lower() for word in list_of_words[1:]]\n",
    "  reviews_positive_dict[list_of_words[0]] = lower_case\n",
    "\n",
    "\n",
    "for review in negative_reviews:\n",
    "  list_of_words = review.split()\n",
    "  lower_case = [word.lower() for word in list_of_words[1:]]\n",
    "  reviews_negative_dict[list_of_words[0]] = lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "dZlk8wfgm6xj"
   },
   "outputs": [],
   "source": [
    "def compute_bias_column(dataset, row_len):\n",
    "  bias = np.repeat(1, row_len)\n",
    "  bias.shape = (row_len,1)\n",
    "  dataset = np.hstack((dataset[:,:7], bias, dataset[:,7:]))\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "pe6O5DmVPGwo"
   },
   "outputs": [],
   "source": [
    "def review_array_init(doc_len,columns):\n",
    "  reviews_array = np.empty((doc_len,columns),dtype=object)\n",
    "  return reviews_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "9TwPaIvkijUj"
   },
   "outputs": [],
   "source": [
    "def compute_six_features(document):\n",
    "    feature1 = compute_counter_feature(document,positive_words_dict)\n",
    "    feature2 = compute_counter_feature(document,negative_words_dict)\n",
    "    feature3 = is_no_present(document)\n",
    "    feature4 = compute_counter_feature(document,pronouns_dict)\n",
    "    feature5 = is_exclamation_present(document)\n",
    "    feature6 = compute_ln_number_of_words(document)\n",
    "    return feature1,feature2,feature3,feature4,feature5,feature6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "EAjviWYOgjB0"
   },
   "outputs": [],
   "source": [
    "def construct_review_dataset(D,reviews_array,polarity):\n",
    "  idx = 0\n",
    "  for doc_id, document in D.items():\n",
    "    feature1,feature2,feature3,feature4,feature5,feature6 = compute_six_features(document)\n",
    "    reviews_array[idx][0] = doc_id\n",
    "    reviews_array[idx][1] = feature1\n",
    "    reviews_array[idx][2] = feature2\n",
    "    reviews_array[idx][3] = feature3\n",
    "    reviews_array[idx][4] = feature4\n",
    "    reviews_array[idx][5] = feature5\n",
    "    reviews_array[idx][6] = feature6\n",
    "    if polarity is not None:\n",
    "      reviews_array[idx][7] = polarity\n",
    "    idx+=1\n",
    "  return reviews_array  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "gyX9tNASQw_y"
   },
   "outputs": [],
   "source": [
    "def compute_review_data_set_positive_negative():\n",
    "\n",
    "  positive_reviews_array = review_array_init(len(reviews_positive_dict),8)\n",
    "  positive_reviews_array = construct_review_dataset(reviews_positive_dict,positive_reviews_array,1)\n",
    "\n",
    "  negative_reviews_array = review_array_init(len(reviews_negative_dict),8)\n",
    "  negative_reviews_array = construct_review_dataset(reviews_negative_dict,negative_reviews_array,0)\n",
    "\n",
    "  reviews_array = np.concatenate((positive_reviews_array,negative_reviews_array),axis=0)\n",
    "  return reviews_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMDsiv2ZJKqb"
   },
   "source": [
    "## Class Probability Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "l-HfkZIIrEFY"
   },
   "outputs": [],
   "source": [
    "def classprob(score): \n",
    "  score = 1/(1+np.exp(-score))\n",
    "  score = np.float128(score) # to handle np.log(0) error increasing the float precision so that it would not become 0 and np.log will have some value\n",
    "  return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybrAePYkJYtP"
   },
   "source": [
    "## Computing the SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "ngXQRgJnrIA2"
   },
   "outputs": [],
   "source": [
    "def compute_sgd(data,learning_rate,bias,epochs,replacement=False):\n",
    "  weights = np.array([0,0,0,0,0,0,0])\n",
    "  weights[6] = bias\n",
    "  rand_indices = []\n",
    "  for i in range(0,epochs):\n",
    "    rand_idx = np.random.choice(len(data), size=1, replace=replacement)[0]\n",
    "    rand_indices.append(rand_idx)\n",
    "    random_sample = data[rand_idx]\n",
    "    dot_product = np.dot(weights, random_sample[1:8])\n",
    "    score = classprob(dot_product)\n",
    "    correct = data[rand_idx,8]\n",
    "    gradient = (score - correct)* random_sample[1:8]\n",
    "    weights = weights - (learning_rate * gradient)\n",
    "  return weights   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "RbOVprO_GtVy"
   },
   "outputs": [],
   "source": [
    "def compute_y_predicted(test_data,weights):\n",
    "  y_predicted = []\n",
    "  y_proba_scores = []\n",
    "  for data in test_data:\n",
    "    dot_product = np.dot(weights, data[1:8])\n",
    "    score = classprob(dot_product)\n",
    "    y_proba_scores.append(score)\n",
    "    if score>0.5:\n",
    "      y_predicted.append(1)\n",
    "    else:\n",
    "      y_predicted.append(0)\n",
    "  return y_predicted,y_proba_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTToAJswJioJ"
   },
   "source": [
    "## Computing accuracy and log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "d6IdT40UILZA"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(test_data,weights):\n",
    "  y_predicted,y_proba = compute_y_predicted(test_data,weights)\n",
    "  N = len(test_data)\n",
    "  error_count = 0\n",
    "  for idx in range(len(test_data)):\n",
    "    if test_data[idx][8]!=y_predicted[idx]:\n",
    "      error_count+=1\n",
    "  accuracy = (len(y_predicted) - error_count)/len(y_predicted)*100\n",
    "  accuracy = round(accuracy,2)\n",
    "\n",
    "  log_loss = 0\n",
    "\n",
    "  for idx in range(len(test_data)):\n",
    "    first_term = test_data[idx][8] * np.log(y_proba[idx])\n",
    "    second_term = (1-test_data[idx][8]) * np.log(1-y_proba[idx])\n",
    "    log_loss = log_loss + (first_term + second_term)\n",
    "  \n",
    "  log_loss = (-1/N)*log_loss\n",
    "  return accuracy,log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgZ7_vMVu1Qf"
   },
   "source": [
    "# Train Test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "r8dztlrdmjS0"
   },
   "outputs": [],
   "source": [
    "def train_test_data_split(reviews_array):\n",
    "  np.random.shuffle(reviews_array)\n",
    "  eighty_percent_index = int(len(reviews_array)*0.8)\n",
    "  train_data = reviews_array[0:eighty_percent_index]\n",
    "  test_data = reviews_array[eighty_percent_index: len(reviews_array)]\n",
    "  return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "iJxJ2ZUIoATv"
   },
   "outputs": [],
   "source": [
    "dataset = compute_review_data_set_positive_negative()\n",
    "formatter_types = ['%s','%d','%d','%d','%d','%d','%.2f','%d']\n",
    "np.savetxt(\"./VenkataramanRavisankar-Ragul-assgn2-part1.csv\", dataset, delimiter=\",\",fmt=formatter_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQlwzfMTry8y",
    "outputId": "586ef926-0c6b-4c77-81c0-8b0e1fa1f013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Train Data\n",
      "\n",
      "The train accuracy is  94.04 %\n",
      "0.21243003937910974509\n",
      "\n",
      "Performance of test Data\n",
      "\n",
      "The test accuracy is  86.84 %\n",
      "0.7979531551957257609\n"
     ]
    }
   ],
   "source": [
    "dataset = compute_bias_column(dataset,len(dataset))\n",
    "train_data, test_data = train_test_data_split(dataset)\n",
    "weights = compute_sgd(train_data,0.01,0.1,15000,False)\n",
    "\n",
    "print('Performance of Train Data\\n')\n",
    "train_accuracy,log_loss = compute_accuracy(train_data,weights)\n",
    "\n",
    "print('The train accuracy is ',train_accuracy,'%')\n",
    "print(log_loss)\n",
    "\n",
    "\n",
    "print('\\nPerformance of test Data\\n')\n",
    "test_accuracy,log_loss = compute_accuracy(test_data,weights)\n",
    "\n",
    "print('The test accuracy is ',test_accuracy,'%')\n",
    "print(log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVI_c1RnqMIL"
   },
   "source": [
    "## Testing the given data file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "FDBa-0UwqTc6"
   },
   "outputs": [],
   "source": [
    "with open('./HW2-testset.txt') as reviews_file:\n",
    "  test_reviews = reviews_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "WUqhq13ZqcRk"
   },
   "outputs": [],
   "source": [
    "test_reviews_dict = dict()\n",
    "\n",
    "for review in test_reviews:\n",
    "  list_of_words = review.split()\n",
    "  lower_case = [word.lower() for word in list_of_words[1:]]\n",
    "  test_reviews_dict[list_of_words[0]] = lower_case\n",
    "\n",
    "\n",
    "test_review_array = review_array_init(len(test_reviews_dict),7)\n",
    "test_review_array = construct_review_dataset(test_reviews_dict,test_review_array,None)\n",
    "test_review_array = compute_bias_column(test_review_array, len(test_reviews_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "XYdk36QQsILa"
   },
   "outputs": [],
   "source": [
    "y_predicted_test, y_proba_test = compute_y_predicted(test_review_array,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "g-Iw_tzSuIpJ"
   },
   "outputs": [],
   "source": [
    "result = [[review[0], \"POS\" if y_label == 1 else \"NEG\"] for review, y_label in zip(test_review_array, y_predicted_test)]\n",
    "formatter_types = ['%s','%s']\n",
    "np.savetxt(\"./VenkataramanRavisankar-Ragul-assgn2-out.txt\", result, delimiter=\"\\t\",fmt=formatter_types)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VenkataramanRavisankar-Ragul-assgn2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
