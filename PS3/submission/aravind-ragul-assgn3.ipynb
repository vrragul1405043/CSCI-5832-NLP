{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Approach.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlhbC6Zd1m48",
        "outputId": "bdcd3923-7369-45c4-dfc5-8242dd94beb2"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3enYs_5PCaA"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.layers import Embedding"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CItaDlhJZGD",
        "outputId": "aeb81f28-8dbd-48b1-ff3f-db9f792cc4b9"
      },
      "source": [
        "print(\"Tensorflow Version:\", tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow Version: 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmqC0olC1TDQ",
        "outputId": "947e94ab-3a76-466e-fe46-74af6d835c1c"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 29 22:49:09 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8OIsfzrYCFc"
      },
      "source": [
        "trainFilePath = '/content/drive/MyDrive/NLP/S21-gene-train.txt'\n",
        "glove50Path = '/content/drive/MyDrive/NLP/glove.6B.50d.txt'\n",
        "modelPath = '/content/drive/MyDrive/NLP/Model/RNN/'\n",
        "testFilePath = '/content/drive/MyDrive/NLP/F21-gene-test.txt'"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl7Am2uBRDkY"
      },
      "source": [
        "def getRawData(path):\n",
        "  with open(path) as f:\n",
        "    rawData = f.readlines()\n",
        "  return rawData  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hORuBWWhSUdX"
      },
      "source": [
        "def processInput(rawData):\n",
        "  tags = []\n",
        "  sentence = []\n",
        "  sentences = []\n",
        "  labels = []\n",
        "  for idx,line in enumerate(rawData):\n",
        "    strippedLine = line.strip()\n",
        "    if(len(strippedLine)>0):\n",
        "      idx,word,tag = strippedLine.split(\"\\t\")\n",
        "      sentence.append(word)\n",
        "      tags.append(tag)\n",
        "    else:\n",
        "      # processedData.append([sentence,tags])\n",
        "      sentences.append(sentence)\n",
        "      labels.append(tags)\n",
        "      sentence = []\n",
        "      tags = []\n",
        "   \n",
        "  return sentences,labels   "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbsvRT6SYLww"
      },
      "source": [
        "rawData = getRawData(trainFilePath)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Z4UpvRXsCq"
      },
      "source": [
        "sentences, labels = processInput(rawData)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-KwJwpgX4G3",
        "outputId": "4cc08937-12d2-44ba-e6c8-d1b7140b2644"
      },
      "source": [
        "print(len(sentences))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjgiejz2PDdJ"
      },
      "source": [
        "xTrain, xTest, yTrain, yTest = train_test_split(sentences,labels, test_size=0.15)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esajdeFlUkV8",
        "outputId": "48861ae1-773b-4aaa-933c-1798a181eed1"
      },
      "source": [
        "print(len(xTrain), len(xTest), len(yTrain), len(yTest))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11725 2070 11725 2070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQl7Xo3mVq4P"
      },
      "source": [
        "## Storing word Frequencies to replace the words with less than threshold count as UNK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVGjPwWiVw9N"
      },
      "source": [
        "trainWordsList = list([tag for sentence in xTrain for tag in sentence])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFFdovUhWAms"
      },
      "source": [
        "trainWordsSet = set(trainWordsList)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdyzwJIeX_8s"
      },
      "source": [
        "np.random.seed(15)\n",
        "toBeUNK = list(np.random.choice(list(trainWordsSet), 30, replace=False)) #replace UNK words add it manually"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS6HkqyzaSWR",
        "outputId": "225f4650-6f5e-47c0-b3ba-d484e33807be"
      },
      "source": [
        "print(len(toBeUNK))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxoNaRaX0v_W",
        "outputId": "d06dbd3b-f52b-44e5-ce5f-afed482c2338"
      },
      "source": [
        "for word in toBeUNK:\n",
        "  print(\"Word\", word, \"Freq\", trainWordsList.count(word))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word TAAT Freq 1\n",
            "Word breathalyzer Freq 1\n",
            "Word multiphoton Freq 1\n",
            "Word daltons Freq 2\n",
            "Word approximation Freq 2\n",
            "Word overnight Freq 2\n",
            "Word sos2 Freq 1\n",
            "Word cyclic Freq 24\n",
            "Word parathyroidectomized Freq 1\n",
            "Word c101F1 Freq 1\n",
            "Word frame Freq 71\n",
            "Word GTPases Freq 5\n",
            "Word MVP Freq 1\n",
            "Word often Freq 22\n",
            "Word decarboxylase Freq 7\n",
            "Word inducibility Freq 13\n",
            "Word organic Freq 7\n",
            "Word cyclohexane Freq 1\n",
            "Word myopia Freq 2\n",
            "Word Intraoperative Freq 1\n",
            "Word CaCl2 Freq 2\n",
            "Word Oc Freq 1\n",
            "Word dissipations Freq 1\n",
            "Word AACAG Freq 1\n",
            "Word VIP Freq 4\n",
            "Word pairwise Freq 1\n",
            "Word tau Freq 6\n",
            "Word adenines Freq 1\n",
            "Word surgical Freq 24\n",
            "Word KGF Freq 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Ts3N0KYzUd"
      },
      "source": [
        "xTrainUpdated = []\n",
        "toBeUNKCopy = toBeUNK\n",
        "\n",
        "for sentence in xTrain:\n",
        "  modified = []\n",
        "  for word in sentence:\n",
        "    if word in toBeUNKCopy:\n",
        "      modified.append('UNK')\n",
        "      toBeUNKCopy.pop(toBeUNKCopy.index(word)) \n",
        "    else:\n",
        "      modified.append(word)\n",
        "  xTrainUpdated.append(modified)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlP7D9nhZtxH",
        "outputId": "e76ae293-077b-4ad6-fb64-74db8407bb42"
      },
      "source": [
        "print(len(xTrainUpdated))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-8ML_PTbYqc",
        "outputId": "6a418f5a-baca-4c5f-ea06-c79449e54443"
      },
      "source": [
        "print(\"UNK Count\", len([word for sentence in xTrainUpdated for word in sentence if word is 'UNK']))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNK Count 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8CxbF8qO4mG"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vvnPqVnQDhE"
      },
      "source": [
        "# Helper method for Tag to Index\n",
        "def getTokenIndexDict(vocabList):\n",
        "    uniqueVocabulary = list(set([tag for sentence in vocabList for tag in sentence]))\n",
        "    tokenToIndex = {token:idx for idx, token in enumerate(uniqueVocabulary)}\n",
        "    indexToToken = {idx:token for idx, token in enumerate(uniqueVocabulary)}\n",
        "    return tokenToIndex, indexToToken"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xnc_DA-QOro"
      },
      "source": [
        "tagToIndex, indexToTag = getTokenIndexDict(yTrain)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiE_7W9zRX5E",
        "outputId": "82cb1109-555a-443b-d7c5-67f2dc4b0990"
      },
      "source": [
        "print(\"Tag to index\", tagToIndex)\n",
        "print(\"Index to Tag\", indexToTag)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag to index {'I': 0, 'B': 1, 'O': 2}\n",
            "Index to Tag {0: 'I', 1: 'B', 2: 'O'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df9C0BhORjim"
      },
      "source": [
        "trainTagEncodings = [[tagToIndex[tag] for tag in sentence] for sentence in yTrain]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Np-RmfRvaq",
        "outputId": "3b05a17d-7f9c-42cf-f478-756dfa5f6902"
      },
      "source": [
        "print(\"Train tag Encodings\", len(trainTagEncodings))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train tag Encodings 11725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOv0cGwNUhMQ"
      },
      "source": [
        "sentenceToIndex, indexToSentence = getTokenIndexDict(xTrainUpdated)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6THAoOY7d-LX"
      },
      "source": [
        "sentenceToIndex['PAD'] = len(sentenceToIndex)\n",
        "indexToSentence[len(indexToSentence)]='PAD'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuhCoq3MUEbc"
      },
      "source": [
        "trainSentenceEncodings = [[sentenceToIndex[tag] for tag in sentence] for sentence in xTrainUpdated]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnoKScxHUvzf",
        "outputId": "0cbdac96-1d75-46b5-e753-f128705f620d"
      },
      "source": [
        "print(\"Train Sentence Encodings\", len(trainSentenceEncodings))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Sentence Encodings 11725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STyBqJ6NcG1z"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhU1N2MCelKi"
      },
      "source": [
        "def getPaddedData(sentenceEncodings, labelEncodings, numTags, maxLen):\n",
        "  padTokens = pad_sequences(sentenceEncodings, maxlen=maxLen, dtype='int32', padding='post', value=sentenceToIndex['PAD'])\n",
        "  padTags = pad_sequences(labelEncodings, maxlen=maxLen, dtype='int32', padding='post', value= tagToIndex[\"O\"])\n",
        "  padTags = [to_categorical(i, num_classes=numTags) for i in padTags]\n",
        "  return padTokens,np.array(padTags)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ4Rk_rQgOue"
      },
      "source": [
        "padTokens, padTags = getPaddedData(trainSentenceEncodings,trainTagEncodings,3,300)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ9i0z0ekwWW",
        "outputId": "4719f918-07cf-4e3f-ee08-c66406b30705"
      },
      "source": [
        "padTokens.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11725, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H46QJXBTqCoS",
        "outputId": "cfdd791b-d68c-47f4-bd9b-e24a42504436"
      },
      "source": [
        "padTags.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11725, 300, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuVN6LOhxrSU"
      },
      "source": [
        "# any([2 in sentence for sentence in padTags])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WMqhpV2OYZs"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJi9yHtYOAP8"
      },
      "source": [
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ8XOomwg1v-"
      },
      "source": [
        "def getModel():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add Embedding layer\n",
        "    model.add(Embedding(input_dim=len(trainWordsSet)+2, output_dim=512))\n",
        "    \n",
        "    # Add bidirectional LSTM\n",
        "    model.add(Bidirectional(LSTM(units=200, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Add LSTM\n",
        "    model.add(LSTM(units=100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    #Optimiser \n",
        "    model.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IrNi9rShlf6",
        "outputId": "93653b79-7117-4259-d693-0c7d10d26866"
      },
      "source": [
        "model = getModel()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 512)         14586880  \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 400)        1140800   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 400)         0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 100)         200400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, None, 100)         0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 3)           303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,928,383\n",
            "Trainable params: 15,928,383\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNT6pgYqhrZD",
        "outputId": "bc0c35fb-ae0b-4097-8cd5-cfff956ae846"
      },
      "source": [
        "model.fit(padTokens, padTags, batch_size=128, verbose=1, epochs=5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 264s 3s/step - loss: 0.0687 - auc: 0.9981\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 254s 3s/step - loss: 0.0255 - auc: 0.9998\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 253s 3s/step - loss: 0.0164 - auc: 0.9999\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 252s 3s/step - loss: 0.0102 - auc: 0.9999\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 253s 3s/step - loss: 0.0070 - auc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4c800a0910>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv2aqcvRjM8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8fb972-443a-4419-91ab-8bb8ece04383"
      },
      "source": [
        "model.save(modelPath)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Model/RNN/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4c8019e810> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4c8dcf5090> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4c8dc99650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZNLGcdSsaoN"
      },
      "source": [
        "##Preparing the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jnCQu0Rt5I2"
      },
      "source": [
        "trainSetUpdatedWords = set([word for sentence in xTrainUpdated for word in sentence])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtFmLzxOsU-I"
      },
      "source": [
        "xTestUpdated = [['UNK' if word not in trainSetUpdatedWords else word for word in sentence]for sentence in xTest]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGzXI_GffOPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ccdd51-df1e-436b-8ae7-563ac9782e07"
      },
      "source": [
        "print(\"Unk Count\", len([word for sentence in xTestUpdated for word in sentence if word=='UNK']))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unk Count 3108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh1y1mQufhig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b8c6e8-dc3c-4bc0-886e-0ba072e87c7a"
      },
      "source": [
        "print(\"Total Words\", len([word for sentence in xTestUpdated for word in sentence]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Words 58322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV3dwJSis7jr"
      },
      "source": [
        "testSentenceEncodings = [[sentenceToIndex[tag] for tag in sentence] for sentence in xTestUpdated]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-OZWueatnNV"
      },
      "source": [
        "testTagEncodings = [[tagToIndex[tag] for tag in sentence] for sentence in yTest]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W470QgU1uoAD"
      },
      "source": [
        "padTestTokens, padTestTags = getPaddedData(testSentenceEncodings,testTagEncodings,3,300)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ6YiEMZuuVu"
      },
      "source": [
        "predictedTagTokens = model.predict(padTestTokens)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLEPsNwdu58d"
      },
      "source": [
        "yPredIndices = np.argmax(predictedTagTokens,axis=2)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBmsZUS7v0lF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f087e2-974a-40da-bdd0-62b2302bc2b9"
      },
      "source": [
        "yPredIndices.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2070, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSzJzDj2vLYC"
      },
      "source": [
        "yPredicted = np.array([[indexToTag[index] for index in sentence] for sentence in yPredIndices])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn5cdXcPwEOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d7e488-7f5f-4681-ec7e-5f554582de30"
      },
      "source": [
        "np.unique(yPredicted)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B', 'I', 'O'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqLrFWzD1cyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7509443f-5445-40af-aca6-0d2a61d5a089"
      },
      "source": [
        "print(yPredicted.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXicoPJG1D-z"
      },
      "source": [
        "ActualValuesPath = '/content/drive/MyDrive/NLP/golden.txt'\n",
        "PredictedValuesPath = '/content/drive/MyDrive/NLP/predicted.txt'\n",
        "TestResultsPath = '/content/drive/MyDrive/NLP/test_results.txt'"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3DK3VG_0KB1"
      },
      "source": [
        "with open(ActualValuesPath, 'w') as actual, open(PredictedValuesPath, 'w') as predict:\n",
        "  for idx, pred in enumerate(yPredicted):\n",
        "    # actualLength = len(yTest[idx])\n",
        "    for lineNumber, word in enumerate(xTest[idx]):\n",
        "      actual.write(f\"{lineNumber+1}\\t{word}\\t{yTest[idx][lineNumber]}\")\n",
        "      actual.write(\"\\n\")\n",
        "      predict.write(f\"{lineNumber+1}\\t{word}\\t{pred[lineNumber]}\")\n",
        "      predict.write(\"\\n\")\n",
        "    actual.write(\"\\n\")\n",
        "    predict.write(\"\\n\")  "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auZ_kuVw-rNK"
      },
      "source": [
        "## Predicting the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjEL_Qky_du2"
      },
      "source": [
        "def processTestData(rawData):\n",
        "  sentence = []\n",
        "  sentences = []\n",
        "  for idx,line in enumerate(rawData):\n",
        "    strippedLine = line.strip()\n",
        "    if(len(strippedLine)>0):\n",
        "      idx,word = strippedLine.split(\"\\t\")\n",
        "      sentence.append(word)\n",
        "      \n",
        "    else:\n",
        "      # processedData.append([sentence,tags])\n",
        "      sentences.append(sentence)\n",
        "      sentence = []\n",
        "  return sentences   "
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMQgDndn-qW0"
      },
      "source": [
        "testRawData = getRawData(testFilePath)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qNarcJN_4WZ"
      },
      "source": [
        "testSentences = processTestData(testRawData)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RflHvLqN__4N",
        "outputId": "7eef1541-eb64-486d-af32-cdd15d52dce8"
      },
      "source": [
        "print(len(testSentences))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d1NiQVUAE9X"
      },
      "source": [
        "xTestDataUpdated = [['UNK' if word not in trainSetUpdatedWords else word for word in sentence]for sentence in testSentences]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzuKXOSYAWR6",
        "outputId": "a56e9358-072c-40d7-bda7-93924a10100c"
      },
      "source": [
        "len(xTestDataUpdated)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "508"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phtuaxOyAXC3",
        "outputId": "3f0deb8a-12d4-40ee-874e-e2c52a54e07c"
      },
      "source": [
        "print(\"UNK word Count\", len([word for sentence in xTestDataUpdated for word in sentence if word=='UNK']))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNK word Count 892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "por_X54cAm9V"
      },
      "source": [
        "testDataSentenceEncodings = [[sentenceToIndex[tag] for tag in sentence] for sentence in xTestDataUpdated]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KJG6J24BIlj"
      },
      "source": [
        "paddedTestData = pad_sequences(testDataSentenceEncodings, maxlen=300, dtype='int32', padding='post', value=sentenceToIndex['PAD'])\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj_ICwl3BUBp",
        "outputId": "2bdfcf80-4565-4612-b132-a94b0237ce49"
      },
      "source": [
        "paddedTestData.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(508, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUhdiUu-BVmG"
      },
      "source": [
        "predictedTestTagTokens = model.predict(paddedTestData)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLxLHK4WBjmL"
      },
      "source": [
        "yTestPredIndices = np.argmax(predictedTestTagTokens,axis=2)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wGW3LyYBpzn"
      },
      "source": [
        "yTestPredicted = np.array([[indexToTag[index] for index in sentence] for sentence in yTestPredIndices])"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TXgQ42xBtUm",
        "outputId": "8089cf2d-14c1-4325-c4f7-159a88a33335"
      },
      "source": [
        "yTestPredicted.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(508, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX-mRsibBu-m",
        "outputId": "3d64e1bc-7a12-4400-dcd9-d58483c640fb"
      },
      "source": [
        "np.unique(yTestPredicted)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B', 'I', 'O'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHZTC7jXCBoB"
      },
      "source": [
        "with open(TestResultsPath, 'w') as testResults:\n",
        "  for idx, pred in enumerate(yTestPredicted):\n",
        "    # actualLength = len(yTest[idx])\n",
        "    for lineNumber, word in enumerate(testSentences[idx]):\n",
        "      testResults.write(f\"{lineNumber+1}\\t{word}\\t{yTestPredicted[idx][lineNumber]}\")\n",
        "      testResults.write(\"\\n\")\n",
        "    testResults.write(\"\\n\") "
      ],
      "execution_count": 79,
      "outputs": []
    }
  ]
}